{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb42c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import gym \n",
    "from tqdm import tqdm \n",
    "from collections import deque\n",
    "rng = np.random.RandomState(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, parent=None, mean=0, var=1):\n",
    "        self.name = name\n",
    "        self.mean = mean  \n",
    "        self.var = var  \n",
    "        self.children = []\n",
    "        self.scores_children = np.array([])\n",
    "        self.nb_children = 0\n",
    "        self.parent = parent\n",
    "        self.level = parent.level + 1 if parent else 0\n",
    "\n",
    "    def get_child_nodes(self):\n",
    "        if not nodes:\n",
    "            nodes = []\n",
    "        for child in self.children:\n",
    "            nodes.append((child.name, child.level, child.nb_children))\n",
    "            nodes.extend(child.get_child_nodes())\n",
    "        return nodes\n",
    "\n",
    "    def get_reward(self):\n",
    "        return self.mean + np.sqrt(self.var) * np.random.normal()\n",
    "\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.levels = [[]]\n",
    "        self.graph = {'root': None,}\n",
    "        self.max_level = 0\n",
    "\n",
    "    def create_node(self, name, parent=None, mean=0, var=1):\n",
    "        return Node(name, parent, mean, var)\n",
    "\n",
    "    def insert(self, parent_node, name, mean, var):\n",
    "        if parent_node is None:\n",
    "            node = self.create_node(name, mean=mean, var=var)\n",
    "            if node.level == 0:\n",
    "                self.root = node\n",
    "                self.graph['root'] = node\n",
    "            return node\n",
    "\n",
    "        node = self.create_node(name, parent_node, mean, var)\n",
    "        self.graph[name] = node\n",
    "        parent_node.children.append(node)\n",
    "        parent_node.nb_children = len(parent_node.children)\n",
    "        parent_node.scores_children = np.full(parent_node.nb_children, 1.0 / parent_node.nb_children)\n",
    "        self.max_level = max(self.max_level, node.level)\n",
    "        return node, parent_node\n",
    "\n",
    "    def get_parent_nodes(self, node):\n",
    "        nodes = [node]\n",
    "        def _recursive_parent_nodes(node, nodes):\n",
    "            if node.parent:\n",
    "                nodes.append(node.parent)\n",
    "                _recursive_parent_nodes(node.parent, nodes)\n",
    "            return nodes\n",
    "        nodes = _recursive_parent_nodes(node, nodes)\n",
    "        nodes.reverse()\n",
    "        return nodes\n",
    "\n",
    "    def get_all_nodes(self):\n",
    "        nodes = [self.root]\n",
    "        def _get_nodes(node):\n",
    "            for child in node.children:\n",
    "                nodes.append(child)\n",
    "                _get_nodes(child)\n",
    "        _get_nodes(self.root)\n",
    "        nodes = sorted(nodes, key=lambda node: node.level)\n",
    "        nodes_names = [node.name for node in nodes]\n",
    "        return nodes\n",
    "\n",
    "    def get_all_leaves(self):\n",
    "        leaves = []\n",
    "        def get_leaves(node):\n",
    "            if len(node.children) == 0:\n",
    "                leaves.append(node)\n",
    "            if node is not None:\n",
    "                for child in node.children:\n",
    "                    get_leaves(child)\n",
    "        get_leaves(self.root)\n",
    "        return leaves\n",
    "\n",
    "    def get_reward_leaf(self, leaf):\n",
    "        parents_leaf = self.get_parent_nodes(leaf)\n",
    "        reward = 0 \n",
    "        for node in parents_leaf:\n",
    "            reward += node.get_reward()\n",
    "        return reward\n",
    "    \n",
    "    def get_reward_leaves(self):\n",
    "        leaves = self.get_all_leaves()\n",
    "        data = []\n",
    "        for leaf in leaves:\n",
    "            data.append([leaf.name, self.get_reward_leaf(leaf)])\n",
    "        return data\n",
    "\n",
    "\n",
    "    def iterative_dfs(self, node_key=None):\n",
    "        if not node_key:\n",
    "            node_key = 'root'\n",
    "        visited = []\n",
    "        stack = deque()\n",
    "        stack.append(node_key)\n",
    "        while stack:\n",
    "            node_key = stack.pop()\n",
    "            if node_key not in visited:\n",
    "                visited.append(node_key)\n",
    "                unvisited = [n.name for n in self.graph[node_key].children if n.name not in visited]\n",
    "                stack.extend(unvisited)\n",
    "        return visited\n",
    "\n",
    "    def iterative_bfs(self, start=None):\n",
    "        if not start:\n",
    "            start = 'root'\n",
    "        visited = []\n",
    "        queue = deque()\n",
    "        queue.append(start)\n",
    "        while queue:\n",
    "            node_key = queue.popleft()\n",
    "            if node_key not in visited:\n",
    "                visited.append(node_key)\n",
    "                unvisited = [n.name for n in self.graph[node_key].children if n.name not in visited]\n",
    "                queue.extend(unvisited)\n",
    "        return visited\n",
    "\n",
    "    def find_max_sum_path(self, root, max_result=-np.infty, max_path=[]):\n",
    "        if root is None:\n",
    "            return 0, max_result\n",
    "        max_sums = [0]\n",
    "        max_paths = [[]]\n",
    "        for child in root.children:\n",
    "            max_sum, idx_max_path = self.find_max_sum_path(child, max_result, max_path)\n",
    "            max_sums.append(max_sum)\n",
    "            max_paths.append(idx_max_path)\n",
    "        sums = root.get_reward() + np.array(max_sums)\n",
    "        idx = np.argmax(sums)\n",
    "        max_result = sums[idx]\n",
    "        max_path = max_paths[idx]\n",
    "        max_path.append(idx)\n",
    "        return max_result, max_path\n",
    "\n",
    "    def find_best_arm_path(self):\n",
    "        max_mean, path = self.find_max_sum_path(self.root)\n",
    "        path = np.array(path[1:])\n",
    "        path = list(path - 1)[::-1]\n",
    "        return max_mean, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c48d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All the nodes in the Tree ---\n",
      "Name: Utilisateur, Drawing reward: 1.0192, Level: 0\n",
      "Name: vehicule, Drawing reward: 0.6502, Level: 1\n",
      "Name: Mobilités Vertes, Drawing reward: 0.7313, Level: 1\n",
      "Name: taxi, Drawing reward: 1.7363, Level: 2\n",
      "Name: uber, Drawing reward: 1.5874, Level: 2\n",
      "Name: bus, Drawing reward: -0.7455, Level: 2\n",
      "Name: tram, Drawing reward: 1.4165, Level: 2\n",
      "Name: covoiturage, Drawing reward: -0.3954, Level: 2\n",
      "Name: avion, Drawing reward: -2.2843, Level: 2\n",
      "Name: train, Drawing reward: 0.3470, Level: 2\n",
      "Name: RER, Drawing reward: 0.6346, Level: 2\n",
      "Name: métro, Drawing reward: -0.1620, Level: 2\n",
      "Name: vélo, Drawing reward: 0.9901, Level: 2\n",
      "Name: marche, Drawing reward: 0.4771, Level: 2\n",
      "Name: course à pied, Drawing reward: 2.2285, Level: 2\n",
      "\n",
      "--- Leaves of the Tree ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'get_reward_leaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m leaves \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mget_all_leaves()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leaf \u001b[38;5;129;01min\u001b[39;00m leaves:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleaf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Drawing reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleaf\u001b[38;5;241m.\u001b[39mget_reward_leaf()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Path with the maximum reward ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m max_sum, best_path \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mfind_best_arm_path()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'get_reward_leaf'"
     ]
    }
   ],
   "source": [
    "tree = Tree()\n",
    "root = tree.insert(parent_node=None, name=\"Utilisateur\", mean=0, var=1)\n",
    "\n",
    "# First Layer\n",
    "vehicule, _ = tree.insert(parent_node=root, name=\"vehicule\", mean=0.8, var=2)\n",
    "mob_verte, _ = tree.insert(parent_node=root, name=\"Mobilités Vertes\", mean=2, var=2)\n",
    "\n",
    "# Second Layer\n",
    "taxi, _ = tree.insert(parent_node=vehicule, name=\"taxi\", mean=0.1, var=2)\n",
    "uber, _ = tree.insert(parent_node=vehicule, name=\"uber\", mean=0.2, var=2)\n",
    "bus, _ = tree.insert(parent_node=vehicule, name=\"bus\", mean=0.05, var=2)\n",
    "tram, _ = tree.insert(parent_node=vehicule, name=\"tram\", mean=0.3, var=2)\n",
    "covoiturage, _ = tree.insert(parent_node=vehicule, name=\"covoiturage\", mean=0.2, var=2)\n",
    "avion, _ = tree.insert(parent_node=vehicule, name=\"avion\", mean=0.1, var=2)\n",
    "train, _ = tree.insert(parent_node=vehicule, name=\"train\", mean=0.4, var=2)\n",
    "rer, _ = tree.insert(parent_node=vehicule, name=\"RER\", mean=0.3, var=2)\n",
    "metro, _ = tree.insert(parent_node=vehicule, name=\"métro\", mean=0.1, var=2)\n",
    "\n",
    "velo, _ = tree.insert(parent_node=mob_verte, name=\"vélo\", mean=1.5, var=2)\n",
    "marche, _ = tree.insert(parent_node=mob_verte, name=\"marche\", mean=1.0, var=2)\n",
    "cap, _ = tree.insert(parent_node=mob_verte, name=\"course à pied\", mean=2.5, var=2)\n",
    "\n",
    "\n",
    "print(\"\\n--- All the nodes in the Tree ---\")\n",
    "all_nodes = tree.get_all_nodes()\n",
    "for node in all_nodes:\n",
    "    print(f\"Name: {node.name}, Drawing reward: {node.get_reward():.4f}, Level: {node.level}\")\n",
    "\n",
    "print(\"\\n--- Leaves of the Tree ---\")\n",
    "data = tree.get_all_leaves()\n",
    "for elements in data:\n",
    "    name = elements[0]\n",
    "    reward = elements[1]\n",
    "    print(f\"Name: {name}, Drawing reward: {reward:.4f}\")\n",
    "\n",
    "print(\"\\n--- Path with the maximum reward ---\")\n",
    "max_sum, best_path = tree.find_best_arm_path()\n",
    "print(f\"Max sum : {max_sum:.4f}\")\n",
    "print(f\"Path : {best_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(environment, agent, Nmc, T):\n",
    "    \"\"\"\n",
    "    Simulate multiple trajectories of agent-environment interaction and record regret.\n",
    "\n",
    "    This function simulates the interaction between a single agent and an environment \n",
    "    over Nmc independent trajectories, each lasting T rounds. It records the pseudo-regret \n",
    "    at each time step by comparing the received reward to the best possible reward.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    environment : object\n",
    "        The environment in which the agent operates. \n",
    "\n",
    "    agent : object\n",
    "        The agent being evaluated. \n",
    "\n",
    "    Nmc : int\n",
    "        Number of Monte Carlo trajectories to simulate.\n",
    "\n",
    "    T : int\n",
    "        Time horizon (number of steps per trajectory).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    agent_id : str\n",
    "        The name or identifier of the agent (via `agent.name()`).\n",
    "\n",
    "    data : np.ndarray\n",
    "        A NumPy array of shape (Nmc, T), where each entry contains the pseudo-regret \n",
    "        (best possible reward minus received reward) at time t in trajectory n.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The pseudo-regret at each time step is computed using the current mean rewards\n",
    "    of the environment arms, which assumes those are fixed and known for evaluation.\n",
    "    \"\"\"\n",
    "    # Initialize the regret matrix\n",
    "    data = np.zeros((Nmc, T))\n",
    "\n",
    "    # Loop over each independent trajectory\n",
    "    for n in range(Nmc):\n",
    "        environment.reset()  # Reset environment if needed (i.i.d. or not)\n",
    "        agent.reset()        # Reset internal state of the agent\n",
    "\n",
    "        for t in range(T):\n",
    "            # Get available actions and let agent choose one\n",
    "            action_set = environment.get_action_set()\n",
    "            action = agent.get_action(action_set)\n",
    "\n",
    "            # Get reward for the chosen action and send it back to the agent\n",
    "            reward = environment.get_reward(action)\n",
    "            agent.receive_reward(action, reward)\n",
    "\n",
    "            # Compute pseudo-regret: best mean - received reward\n",
    "            means = environment.get_means()\n",
    "            best_reward = np.max(means)\n",
    "            data[n, t] = best_reward - reward\n",
    "\n",
    "    return agent.name(), data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(environment, agents, Nmc, T):\n",
    "    \"\"\"\n",
    "    Run multiple simulations of each agent interacting with the environment and record regret.\n",
    "\n",
    "    This function evaluates a list of agents by having them interact with a given environment\n",
    "    over multiple Monte Carlo simulations, each lasting for a fixed time horizon.\n",
    "    For each agent, it computes and stores the regret over time for each trajectory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    environment : object\n",
    "        The environment in which the agents operate. \n",
    "    \n",
    "    agents : list\n",
    "        A list of agent instances. Each agent must implement `reset()`, `get_action()`,\n",
    "        `receive_reward(action, reward)`, and `name()` methods.\n",
    "    \n",
    "    Nmc : int\n",
    "        Number of Monte Carlo simulations to run for each agent.\n",
    "    \n",
    "    T : int\n",
    "        Time horizon (number of rounds) for each simulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_data : dict\n",
    "        A dictionary mapping each agent's name (str) to a NumPy array of shape (Nmc, T),\n",
    "        containing the regret at each time step for each Monte Carlo run.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "\n",
    "    for agent in agents:\n",
    "        # Run Nmc simulations for the current agent and compute regrets\n",
    "        agent_id, regrets = play(environment, agent, Nmc, T)\n",
    "\n",
    "        # Store the results in the dictionary under the agent's name\n",
    "        all_data[agent_id] = regrets\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e515703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticEnvironment(gym.Env):\n",
    "    \"\"\"\n",
    "    The Environment class represents a decision-making environment with a tree structure.\n",
    "    The tree is generated dynamically and rewards are assigned to each node based on its level and value. \n",
    "    The environment allows the computation of rewards based on nodes and paths, \n",
    "    and finds the best strategy for decision-making.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    env_rng : numpy.random.RandomState\n",
    "        A random state generator used for sampling rewards.\n",
    "    \n",
    "    nb_layers : int \n",
    "        Number of layers for the Tree. \n",
    "        Example 3 \n",
    "\n",
    "    nb_nodes_per_layer : list\n",
    "        Number of nodes per layer for the Tree. \n",
    "        Example [1, 2, 5]\n",
    "\n",
    "    mus : list\n",
    "        Mean of the distribution for each layer. \n",
    "        Example [0, [1, 4], [[0.1, 0.3], [0.2, 0.1, 0.1]]]\n",
    "    \n",
    "    \"\"\" \n",
    "    def __init__(self, nb_nodes_per_layer, mus):\n",
    "        self.env_rng = np.random.RandomState(2025)  # Use a fixed seed for reproducibility\n",
    "        self.nb_layers = len(nb_nodes_per_layer) \n",
    "        self.nb_nodes_per_layer = nb_nodes_per_layer\n",
    "        self.mus = mus\n",
    "        self.sigma = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.tree = Tree()\n",
    "        self.generate_tree()\n",
    "        return [0]\n",
    "    \n",
    "    def _initialize_tree(self):\n",
    "        \"\"\"\n",
    "        Initializes the tree by creating the root node.\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        self.tree = Tree()\n",
    "        self.root = self.tree.insert(self.root, ('root', self.mus[0])) \n",
    "\n",
    "    def generate_tree(self):\n",
    "        self._initialize_tree()\n",
    "\n",
    "        def build_layer(parents, mus_layer, layer_idx):\n",
    "            current_layer_nodes = []\n",
    "\n",
    "            if len(parents) != len(mus_layer):\n",
    "                raise ValueError(f\"Layer {layer_idx}: expected {len(parents)} parents, got {len(mus_layer)} mus sublists\")\n",
    "            \n",
    "            for parent_idx, (parent_node, child_mus_list) in enumerate(zip(parents, mus_layer)):\n",
    "                if not isinstance(child_mus_list, list):\n",
    "                    raise ValueError(f\"Layer {layer_idx}: mus[{layer_idx}][{parent_idx}] should be a list of floats\")\n",
    "\n",
    "                for child_idx, mu in enumerate(child_mus_list):\n",
    "                    value = self.env_rng.normal(mu, self.sigma)\n",
    "                    node_data = (f\"Node_{layer_idx}_{parent_idx}_{child_idx}\", value)\n",
    "                    node, _ = self.tree.insert(parent_node, node_data)\n",
    "                    current_layer_nodes.append(node)\n",
    "            return current_layer_nodes\n",
    "\n",
    "        if not isinstance(self.mus[0], (int, float)):\n",
    "            raise ValueError(\"mus[0] must be a scalar for root node.\")\n",
    "        self.root.data = (\"root\", self.env_rng.normal(self.mus[0], self.sigma))\n",
    "\n",
    "        parents = [self.root]\n",
    "\n",
    "        for layer_idx in range(1, len(self.mus)):\n",
    "            mus_layer = self.mus[layer_idx]\n",
    "\n",
    "            if layer_idx == 1:\n",
    "                current_layer_nodes = []\n",
    "                for idx, mu in enumerate(mus_layer):\n",
    "                    value = self.env_rng.normal(mu, self.sigma)\n",
    "                    node_data = (f\"Node_{layer_idx}_{idx}\", value)\n",
    "                    node, _ = self.tree.insert(self.root, node_data)\n",
    "                    current_layer_nodes.append(node)\n",
    "                parents = current_layer_nodes\n",
    "            else:\n",
    "                parents = build_layer(parents, mus_layer, layer_idx)\n",
    "\n",
    "        return self.tree\n",
    "    \n",
    "    def get_action_set(self):\n",
    "        return list(np.arange(len(self.tree.get_all_nodes())))\n",
    "    \n",
    "    def get_reward(self, action):\n",
    "        \"\"\"Obtain the reward given an action.\"\"\"\n",
    "        # The action is a path, with indexes corresponding to the nodes \n",
    "        node = self.tree.graph.get(action)\n",
    "        if node:\n",
    "            total_reward = 0\n",
    "            path_node = node\n",
    "            while path_node:\n",
    "                total_reward += path_node.get_reward()\n",
    "                path_node = path_node.parent\n",
    "            return total_reward\n",
    "        return 0\n",
    "    \n",
    "    def get_best_strategy_reward(self):\n",
    "        all_rewards = [node.mean for node in self.tree.get_all_nodes()]\n",
    "        return np.max(all_rewards)\n",
    "\n",
    "    def get_reward_by_node(self, node):\n",
    "        return node.get_reward()\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = self.get_reward(action)\n",
    "        done = True  \n",
    "        return [0], reward, done, {}\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def visualize_tree(self):\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        def add_edges(node, parent_name=None):\n",
    "            if node is not None:\n",
    "                G.add_node(node.name, level=node.level) \n",
    "                if parent_name:\n",
    "                    G.add_edge(parent_name, node.name)  \n",
    "                for child in node.children:  \n",
    "                    add_edges(child, node.name)\n",
    "\n",
    "        add_edges(self.tree.root)\n",
    "        \n",
    "\n",
    "        color_map = plt.cm.get_cmap(\"viridis\", self.tree.max_level + 1)\n",
    "        levels = [G.nodes[node]['level'] for node in G.nodes]\n",
    "        norm = plt.Normalize(vmin=min(levels), vmax=max(levels))\n",
    "        node_colors = [color_map(norm(G.nodes[node]['level'])) for node in G.nodes]\n",
    "        pos = nx.spring_layout(G, seed=2025)  \n",
    "        labels = nx.get_node_attributes(G, 'label')\n",
    "        nx.draw(G, pos, with_labels=True, node_size=3000, node_color=node_colors, font_size=10, font_weight='bold')\n",
    "        sm = plt.cm.ScalarMappable(cmap=color_map, norm=norm)\n",
    "        sm.set_array([])\n",
    "        level_labels = [f\"Couche {i}\" for i in range(self.tree.max_level + 1)]\n",
    "        cbar = plt.colorbar(sm, shrink=2, aspect=2)\n",
    "        cbar.set_ticks(np.linspace(0, 1, self.tree.max_level + 1))  \n",
    "        cbar.set_ticklabels(level_labels)  \n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
